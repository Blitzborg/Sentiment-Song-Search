{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_IR_Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYMyjVKVIiiF",
        "outputId": "fe95c370-5bfe-48bb-c809-2a8d824587d7"
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize  \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "import re \n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from textblob import TextBlob\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('wordnet')\n",
        "from nltk.probability import FreqDist\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "XJweM7zYIjkI",
        "outputId": "53d7361e-f5f8-492b-ed1e-35f5094cca5c"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/train_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song_name</th>\n",
              "      <th>lyrics_processed</th>\n",
              "      <th>link</th>\n",
              "      <th>date</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Description</th>\n",
              "      <th>Featured Artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>explicit_rating</th>\n",
              "      <th>year</th>\n",
              "      <th>decade</th>\n",
              "      <th>new</th>\n",
              "      <th>blob</th>\n",
              "      <th>polarity</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>blob_score</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>compound</th>\n",
              "      <th>SI Score</th>\n",
              "      <th>NLTK Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adele</td>\n",
              "      <td>Hello</td>\n",
              "      <td>hello it's me i was wondering if after all the...</td>\n",
              "      <td>http://www.youtube.com/watch?v=YQHsXMglC9A</td>\n",
              "      <td>2015-10-23</td>\n",
              "      <td>negative</td>\n",
              "      <td>In this digital and single-driven age, it’s ve...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Verse 1]\\nHello, it's me\\nI was wondering if ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2010s</td>\n",
              "      <td>hello wondering years like meet go everything ...</td>\n",
              "      <td>Sentiment(polarity=-0.17681159420289855, subje...</td>\n",
              "      <td>-0.176812</td>\n",
              "      <td>0.513043</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.712</td>\n",
              "      <td>0.103</td>\n",
              "      <td>-0.6808</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adele</td>\n",
              "      <td>Someone Like You</td>\n",
              "      <td>i heard that you're settled down that you foun...</td>\n",
              "      <td>http://www.youtube.com/watch?v=hLQl3WQQoQ0</td>\n",
              "      <td>2011-01-24</td>\n",
              "      <td>negative</td>\n",
              "      <td>In this digital and single-driven age, it’s ve...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Verse 1]\\nI heard that you're settled down\\nT...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>2010s</td>\n",
              "      <td>heard settled found girl married heard dreams ...</td>\n",
              "      <td>Sentiment(polarity=0.28095238095238095, subjec...</td>\n",
              "      <td>0.280952</td>\n",
              "      <td>0.442857</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.234</td>\n",
              "      <td>0.451</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.9574</td>\n",
              "      <td>positive</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adele</td>\n",
              "      <td>When We Were Young</td>\n",
              "      <td>everybody loves the things you do from the way...</td>\n",
              "      <td>http://www.youtube.com/watch?v=WyVS2N8aK-U</td>\n",
              "      <td>2015-11-20</td>\n",
              "      <td>neutral</td>\n",
              "      <td>In this digital and single-driven age, it’s ve...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Verse 1]\\nEverybody loves the things you do\\n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2010s</td>\n",
              "      <td>everybody loves things way talk way move every...</td>\n",
              "      <td>Sentiment(polarity=0.062037037037037064, subje...</td>\n",
              "      <td>0.062037</td>\n",
              "      <td>0.417824</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.538</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.9867</td>\n",
              "      <td>positive</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adele</td>\n",
              "      <td>All I Ask</td>\n",
              "      <td>i will leave my heart at the door i won't say ...</td>\n",
              "      <td>http://www.youtube.com/watch?v=GcHVHPPWkvI</td>\n",
              "      <td>2015-11-20</td>\n",
              "      <td>negative</td>\n",
              "      <td>In this digital and single-driven age, it’s ve...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Verse 1]\\nI will leave my heart at the door\\n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>2010s</td>\n",
              "      <td>leave heart door say word said know play prete...</td>\n",
              "      <td>Sentiment(polarity=-0.19642857142857142, subje...</td>\n",
              "      <td>-0.196429</td>\n",
              "      <td>0.520635</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.228</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.328</td>\n",
              "      <td>0.9062</td>\n",
              "      <td>positive</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adele</td>\n",
              "      <td>Rolling in the Deep</td>\n",
              "      <td>there's a fire starting in my heart reaching a...</td>\n",
              "      <td>http://www.youtube.com/watch?v=rYEDA3JcQqw</td>\n",
              "      <td>2010-11-29</td>\n",
              "      <td>negative</td>\n",
              "      <td>In this digital and single-driven age, it’s ve...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Verse 1]\\nThere's a fire starting in my heart...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>2010s</td>\n",
              "      <td>fire starting heart reaching fever pitch bring...</td>\n",
              "      <td>Sentiment(polarity=0.0859375, subjectivity=0.4...</td>\n",
              "      <td>0.085938</td>\n",
              "      <td>0.449132</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.177</td>\n",
              "      <td>0.542</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.9926</td>\n",
              "      <td>positive</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist            song_name  ...  SI Score   NLTK Class\n",
              "0  Adele                Hello  ...   neutral      neutral\n",
              "1  Adele     Someone Like You  ...  positive  non-neutral\n",
              "2  Adele   When We Were Young  ...  positive  non-neutral\n",
              "3  Adele            All I Ask  ...  positive  non-neutral\n",
              "4  Adele  Rolling in the Deep  ...  positive  non-neutral\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWpN-d3zIpB1"
      },
      "source": [
        "df['index'] = df.index"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArLb3-gSJr1C"
      },
      "source": [
        "Explortory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg2YujDYJoF4",
        "outputId": "6749e809-1210-4e44-a4b5-16d6832f1400"
      },
      "source": [
        "df['NLTK Class'].value_counts()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "non-neutral    5172\n",
              "neutral        4829\n",
              "Name: NLTK Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEYMMoExOJGk",
        "outputId": "cb1dafb8-f8b8-43b9-c8e2-05d34239daa6"
      },
      "source": [
        "df['sentiment'][4211] = df['sentiment'][4210]\n",
        "df['sentiment'][4212] = df['sentiment'][4210]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXofQ-FhVRN7",
        "outputId": "708f3baf-b248-4e0a-e30f-d6abc215514e"
      },
      "source": [
        "df_new = df[(df['blob_score'] == 'neutral')]\n",
        "df_new = df_new[(df_new['NLTK Class'] == 'non-neutral')]\n",
        "for i in df_new['song_name']:\n",
        "  for j in range(len(df)):\n",
        "    if df['song_name'][j] == i:\n",
        "      df['blob_score'][j] = df['SI Score'][j]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkN6REowV5EF",
        "outputId": "c3aa1f9d-d920-4a38-dbc3-76045a456a8d"
      },
      "source": [
        "df_neu = df[(df['NLTK Class'] == 'neutral')]\n",
        "len(df_neu)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVyAoF7vVh_J",
        "outputId": "36d09e64-a668-47f2-b7e6-59b6cbde54ca"
      },
      "source": [
        "df_test = df[(df['NLTK Class'] == 'non-neutral')]\n",
        "len(df_test)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6xXRbCGWIEF"
      },
      "source": [
        "x_test = list(df_test['lyrics_processed'])\n",
        "y_test = list(df_test['blob_score'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmLzIM-9Q3oz",
        "outputId": "64ad527e-35cb-43ac-965e-3692cf67f02b"
      },
      "source": [
        "df_real = df[df['sentiment'].isna()]\n",
        "len(df_real)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtMVNTfqSvP_",
        "outputId": "c16f71a5-3982-4aab-a9b5-f6329c956079"
      },
      "source": [
        "df_real['NLTK Class'].value_counts()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "non-neutral    4664\n",
              "neutral        4337\n",
              "Name: NLTK Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgUXITItJuzF",
        "outputId": "db61ffd4-456d-4c2d-b0a6-445e6caa510d"
      },
      "source": [
        "df_evaluation = df[df['sentiment'].notna()]\n",
        "len(df_evaluation)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPi5YoUVOC5o",
        "outputId": "bbd361a1-5732-489d-8765-b20fffcf567a"
      },
      "source": [
        "df_senti = df_real[(df_real['NLTK Class'] == 'non-neutral')]\n",
        "df_senti['index'] = df_senti.index\n",
        "len(df_senti)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8AxrORpJwgQ"
      },
      "source": [
        "x_train = list(df_senti['lyrics_processed'])\n",
        "y_train = list(df_senti['blob_score'])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "UGcpSCmJNaMr",
        "outputId": "20c0e66b-bf92-4f35-aa07-0d3f4405eeef"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "import pandas as pd\n",
        "\n",
        "eval_list = []\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    training_data: list, test_data: list, iterations: int = 10\n",
        ") -> None:\n",
        "    # Build pipeline\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    if \"textcat\" not in nlp.pipe_names:\n",
        "        textcat = nlp.create_pipe(\n",
        "            \"textcat\", config={\"architecture\": \"simple_cnn\"}\n",
        "        )\n",
        "        nlp.add_pipe(textcat, last=True)\n",
        "    else:\n",
        "        textcat = nlp.get_pipe(\"textcat\")\n",
        "\n",
        "    textcat.add_label(\"pos\")\n",
        "    textcat.add_label(\"neg\")\n",
        "\n",
        "    # Train only textcat\n",
        "    training_excluded_pipes = [\n",
        "        pipe for pipe in nlp.pipe_names if pipe != \"textcat\"\n",
        "    ]\n",
        "    with nlp.disable_pipes(training_excluded_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "        # Training loop\n",
        "        print(\"Beginning training\")\n",
        "        print(\"Loss\\tPrecision\\tRecall\\tF-score\")\n",
        "        batch_sizes = compounding(\n",
        "            4.0, 32.0, 1.001\n",
        "        )  # A generator that yields infinite series of input numbers\n",
        "        for i in range(iterations):\n",
        "            print(f\"Training iteration {i}\")\n",
        "            loss = {}\n",
        "            random.shuffle(training_data)\n",
        "            batches = minibatch(training_data, size=batch_sizes)\n",
        "            for batch in batches:\n",
        "                text, labels = zip(*batch)\n",
        "                nlp.update(text, labels, drop=0.2, sgd=optimizer, losses=loss)\n",
        "            with textcat.model.use_params(optimizer.averages):\n",
        "                evaluation_results = evaluate_model(\n",
        "                    tokenizer=nlp.tokenizer,\n",
        "                    textcat=textcat,\n",
        "                    test_data=test_data,\n",
        "                )\n",
        "                print(\n",
        "                    f\"{loss['textcat']}\\t{evaluation_results['precision']}\"\n",
        "                    f\"\\t{evaluation_results['recall']}\"\n",
        "                    f\"\\t{evaluation_results['f-score']}\"\n",
        "                )\n",
        "\n",
        "    # Save model\n",
        "    with nlp.use_params(optimizer.averages):\n",
        "        nlp.to_disk(\"model_artifacts\")\n",
        "\n",
        "\n",
        "def evaluate_model(tokenizer, textcat, test_data: list) -> dict:\n",
        "    reviews, labels = zip(*test_data)\n",
        "    reviews = (tokenizer(review) for review in reviews)\n",
        "    true_positives = 0\n",
        "    false_positives = 1e-8  # Can't be 0 because of presence in denominator\n",
        "    true_negatives = 0\n",
        "    false_negatives = 1e-8\n",
        "    for i, review in enumerate(textcat.pipe(reviews)):\n",
        "        true_label = labels[i][\"cats\"]\n",
        "        for predicted_label, score in review.cats.items():\n",
        "            # Every cats dictionary includes both labels, you can get all\n",
        "            # the info you need with just the pos label\n",
        "            if predicted_label == \"neg\":\n",
        "                continue\n",
        "            if score >= 0.5 and true_label[\"pos\"]:\n",
        "                true_positives += 1\n",
        "            elif score >= 0.5 and true_label[\"neg\"]:\n",
        "                false_positives += 1\n",
        "            elif score < 0.5 and true_label[\"neg\"]:\n",
        "                true_negatives += 1\n",
        "            elif score < 0.5 and true_label[\"pos\"]:\n",
        "                false_negatives += 1\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        f_score = 0\n",
        "    else:\n",
        "        f_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f-score\": f_score}\n",
        "\n",
        "\n",
        "def test_model(input_data):\n",
        "    #  Load saved trained model\n",
        "    loaded_model = spacy.load(\"model_artifacts\")\n",
        "    # Generate prediction\n",
        "    parsed_text = loaded_model(input_data)\n",
        "    # Determine prediction to return\n",
        "    if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
        "        prediction = \"Positive\"\n",
        "        score = parsed_text.cats[\"pos\"]\n",
        "    else:\n",
        "        prediction = \"Negative\"\n",
        "        score = parsed_text.cats[\"neg\"]\n",
        "    print(\n",
        "        # f\"Review text: {input_data}\\nPredicted sentiment: {prediction}\"\n",
        "        f\"\\tScore:{score} \\nPredicted sentiment: {prediction} \"\n",
        "    )\n",
        "\n",
        "\n",
        "# pos (0) - opinion, neg (1) - no opinion\n",
        "def load_training_custom():\n",
        "  items = []\n",
        "  for i in range(len(x_train)):\n",
        "    song = x_train[i]\n",
        "    sentiment = y_train[i]\n",
        "    cats_obj = {\n",
        "        'cats': {\n",
        "            'neg' : sentiment == 'negative',\n",
        "            'pos' : sentiment == 'positive'\n",
        "        }\n",
        "    }\n",
        "    this_item = (song, cats_obj)\n",
        "    items.append(this_item)\n",
        "  random.shuffle(items)\n",
        "  train_items = items[0:int(0.8*len(items))]\n",
        "  validation_items = items[int(0.8*len(items)):len(items)]\n",
        "  final_items = (train_items, validation_items)\n",
        "  return final_items\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train, test = load_training_custom()\n",
        "    print(\"Training model\")\n",
        "    train_model(train, test)\n",
        "    df1 = pd.DataFrame(eval_list)\n",
        "    pd.DataFrame.plot(df1)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model\n",
            "Beginning training\n",
            "Loss\tPrecision\tRecall\tF-score\n",
            "Training iteration 0\n",
            "15.261721247202797\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 1\n",
            "2.573039759921365\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 2\n",
            "0.8802587319064233\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 3\n",
            "0.6542133309412748\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 4\n",
            "0.22279891384823713\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 5\n",
            "0.13498915523814503\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 6\n",
            "0.08766252985515166\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 7\n",
            "0.0694435788464034\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 8\n",
            "0.06364724278682843\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Training iteration 9\n",
            "0.06440481101162732\t0.7041800643011342\t0.9999999999847793\t0.8264150943292276\n",
            "Testing model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-fce3c906f4b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: test_model() missing 1 required positional argument: 'input_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V399pSmlb9y9",
        "outputId": "72ffe7f9-25b8-4bbf-ed1c-d0d3b4ada21a"
      },
      "source": [
        "!unzip file.zip"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  file.zip\n",
            "   creating: content/model_artifacts/\n",
            "   creating: content/model_artifacts/textcat/\n",
            "  inflating: content/model_artifacts/textcat/cfg  \n",
            "  inflating: content/model_artifacts/textcat/model  \n",
            "   creating: content/model_artifacts/vocab/\n",
            "  inflating: content/model_artifacts/vocab/strings.json  \n",
            "  inflating: content/model_artifacts/vocab/lookups.bin  \n",
            " extracting: content/model_artifacts/vocab/key2row  \n",
            "  inflating: content/model_artifacts/vocab/vectors  \n",
            "  inflating: content/model_artifacts/vocab/lexemes.bin  \n",
            "   creating: content/model_artifacts/tagger/\n",
            "  inflating: content/model_artifacts/tagger/tag_map  \n",
            "  inflating: content/model_artifacts/tagger/cfg  \n",
            "  inflating: content/model_artifacts/tagger/model  \n",
            "   creating: content/model_artifacts/ner/\n",
            "  inflating: content/model_artifacts/ner/cfg  \n",
            "  inflating: content/model_artifacts/ner/model  \n",
            "  inflating: content/model_artifacts/ner/moves  \n",
            "  inflating: content/model_artifacts/tokenizer  \n",
            "  inflating: content/model_artifacts/meta.json  \n",
            "   creating: content/model_artifacts/parser/\n",
            "  inflating: content/model_artifacts/parser/cfg  \n",
            "  inflating: content/model_artifacts/parser/model  \n",
            "  inflating: content/model_artifacts/parser/moves  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRCQ5X2nJ0TC"
      },
      "source": [
        "\n",
        "def test_model_sentiment(x_test):\n",
        "    spacy_label = []\n",
        "    #  Load saved trained model\n",
        "    loaded_model = spacy.load(\"/content/content/model_artifacts\")\n",
        "    # Generate prediction\n",
        "    for i in tqdm(range(len(x_test))):\n",
        "      parsed_text = loaded_model(x_test[i])\n",
        "      # Determine prediction to return\n",
        "      if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
        "          prediction = 1\n",
        "          score = parsed_text.cats[\"pos\"]\n",
        "      else:\n",
        "          prediction = 0\n",
        "          score = parsed_text.cats[\"neg\"]\n",
        "      spacy_label.append(prediction)\n",
        "    # print(\n",
        "    #     # f\"Review text: {input_data}\\nPredicted sentiment: {prediction}\"\n",
        "    #     # f\"\\tScore:{score} \\nPredicted sentiment: {prediction} \"\n",
        "\n",
        "    # )\n",
        "    return spacy_label\n",
        "  "
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XYNqXyZNPiV",
        "outputId": "2f352e57-0aba-438a-def3-6b192e38fe86"
      },
      "source": [
        "spacy_final = test_model_sentiment(x_test)\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5172/5172 [06:28<00:00, 13.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qaaDFvDUWgf"
      },
      "source": [
        "Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFODPD7NT-Bw",
        "outputId": "c138affc-0767-4a23-a9fd-6a70388a6023"
      },
      "source": [
        "final_preds = []\n",
        "for i in tqdm(range(len(x_test))):\n",
        "  song = x_test[i]\n",
        "  # spacy1 = test_model(song)\n",
        "  textblob = round((TextBlob(song).sentiment.polarity + 1)/2)\n",
        "  scores = sid.polarity_scores(song)\n",
        "  if scores['neg'] > scores['pos']:\n",
        "    nltk_score = 0\n",
        "  else:\n",
        "    nltk_score = 1\n",
        "  if textblob + spacy_final[i] + nltk_score == 3:\n",
        "    final_preds.append(\"positive\")\n",
        "  elif textblob + spacy_final[i] + nltk_score == 2:\n",
        "    final_preds.append(\"positive\")\n",
        "  else:\n",
        "    final_preds.append(\"negative\")\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5172/5172 [00:34<00:00, 148.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP12wsH3Uam7",
        "outputId": "4f56b5b4-3035-469f-cc27-3e7579399677"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(final_preds)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 1426, 'positive': 3746})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9sHyLkQUedC",
        "outputId": "58c2b728-8117-437c-c9b3-f6c1b53a95d4"
      },
      "source": [
        "df_test['sentiment'] = final_preds"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56z_VNdvUziE",
        "outputId": "bc965556-64d1-4cb8-f3b6-58fc1ffa9e08"
      },
      "source": [
        "df_neu['sentiment'] = 'neutral'"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGWVbzGkWd4S",
        "outputId": "ead79836-1588-45ea-8883-2b86ddeeb444"
      },
      "source": [
        "df_final  = df_test.append(df_neu,ignore_index = False)\n",
        "df_final =  df_final.sort_values(by=['index'])\n",
        "print(len(df_final))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEuMRcl3XZfw"
      },
      "source": [
        "df_pred_label = pd.DataFrame()\n",
        "df_pred_label['song_name'] = df_final['song_name']\n",
        "df_pred_label['sentiment'] = df_final['sentiment']\n",
        "df_pred_label['index'] = df_final['index']"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X5X3GcAXZds"
      },
      "source": [
        "df_real_label = pd.DataFrame()\n",
        "df_real_label['song_name'] = df_evaluation['song_name']\n",
        "df_real_label['sentiment'] = df_evaluation['sentiment']\n",
        "df_real_label['index'] = df_evaluation['index']\n"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NA6fhyJjFZK",
        "outputId": "aacd9abb-f465-4893-bffa-dd8532e9283c"
      },
      "source": [
        "print(len(df_pred_label))\n",
        "print(len(df_real_label))"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbZFHEuXi9Td",
        "outputId": "91ec31d2-f675-4604-b628-4031532d09ad"
      },
      "source": [
        "df_real_label['sentiment'].value_counts()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     500\n",
              "positive    250\n",
              "negative    250\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-LN0madXZb5",
        "outputId": "1881c991-9015-41e6-831a-5263e23d51d7"
      },
      "source": [
        "df_acc = df_real_label.merge(df_pred_label, on ='index',how='left')\n",
        "len(df_acc)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Qdmrsj2DeGEi",
        "outputId": "a3aa3dd5-7692-4e37-eef4-9acc4b7a2ac8"
      },
      "source": [
        "df_acc"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_name_x</th>\n",
              "      <th>sentiment_x</th>\n",
              "      <th>index</th>\n",
              "      <th>song_name_y</th>\n",
              "      <th>sentiment_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>Hello</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Someone Like You</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>Someone Like You</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When We Were Young</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>When We Were Young</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All I Ask</td>\n",
              "      <td>positive</td>\n",
              "      <td>3</td>\n",
              "      <td>All I Ask</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rolling in the Deep</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>Rolling in the Deep</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Preacher</td>\n",
              "      <td>neutral</td>\n",
              "      <td>6074</td>\n",
              "      <td>Preacher</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Burning Bridges</td>\n",
              "      <td>positive</td>\n",
              "      <td>6075</td>\n",
              "      <td>Burning Bridges</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Truth to Power</td>\n",
              "      <td>neutral</td>\n",
              "      <td>6082</td>\n",
              "      <td>Truth to Power</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Oh My My</td>\n",
              "      <td>positive</td>\n",
              "      <td>6091</td>\n",
              "      <td>Oh My My</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>All These Things</td>\n",
              "      <td>neutral</td>\n",
              "      <td>6097</td>\n",
              "      <td>All These Things</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             song_name_x sentiment_x  index          song_name_y sentiment_y\n",
              "0                  Hello    negative      0                Hello     neutral\n",
              "1       Someone Like You    positive      1     Someone Like You    positive\n",
              "2     When We Were Young    positive      2   When We Were Young    positive\n",
              "3              All I Ask    positive      3            All I Ask    positive\n",
              "4    Rolling in the Deep    positive      4  Rolling in the Deep    positive\n",
              "..                   ...         ...    ...                  ...         ...\n",
              "995             Preacher     neutral   6074             Preacher     neutral\n",
              "996      Burning Bridges    positive   6075      Burning Bridges    positive\n",
              "997       Truth to Power     neutral   6082       Truth to Power     neutral\n",
              "998             Oh My My    positive   6091             Oh My My     neutral\n",
              "999     All These Things     neutral   6097     All These Things    negative\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq37TgU1m0Pd"
      },
      "source": [
        "Results of Evaluation Set and Machine Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a74RyGWXZZz",
        "outputId": "2874545a-b5e1-424a-b443-cbf73de67db8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "y_pred = list(df_acc['sentiment_x'])\n",
        "y_actual = list(df_acc['sentiment_y'])\n",
        "print('Confusion Matrix: \\n',confusion_matrix(y_pred, y_actual))\n",
        "print('accuracy: ' + str(accuracy_score(y_pred, y_actual)))\n",
        "print('F1 Score: '+ str(f1_score(y_pred, y_actual, average='macro')))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[ 85  43  38]\n",
            " [ 18 405  66]\n",
            " [  7  44 294]]\n",
            "accuracy: 0.784\n",
            "F1 Score: 0.7443387914169323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEOX-F09gexH"
      },
      "source": [
        "df_final.to_csv('./machine_predictions.csv',index=False)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ_k-H2Rm50y"
      },
      "source": [
        "Submission File\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvoBm3JNm8iE",
        "outputId": "46cb4678-40e1-49b1-ab69-a25fe5051a37"
      },
      "source": [
        "df_new_neu = df_real[df_real['NLTK Class'] == 'neutral']\n",
        "len(df_new_neu)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnQC_-3-nRtp",
        "outputId": "07d98fb6-0781-43c2-a9d2-b21d1512c3b5"
      },
      "source": [
        "spacy_final = test_model_sentiment(x_train)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4664/4664 [05:57<00:00, 13.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRvzd4VanaOa",
        "outputId": "9ad83dce-cf34-41cb-914b-ee9de4851f0e"
      },
      "source": [
        "final_preds = []\n",
        "for i in tqdm(range(len(x_train))):\n",
        "  song = x_train[i]\n",
        "  # spacy1 = test_model(song)\n",
        "  textblob = round((TextBlob(song).sentiment.polarity + 1)/2)\n",
        "  scores = sid.polarity_scores(song)\n",
        "  if scores['neg'] > scores['pos']:\n",
        "    nltk_score = 0\n",
        "  else:\n",
        "    nltk_score = 1\n",
        "  if textblob + spacy_final[i] + nltk_score == 3:\n",
        "    final_preds.append(\"positive\")\n",
        "  elif textblob + spacy_final[i] + nltk_score == 2:\n",
        "    final_preds.append(\"positive\")\n",
        "  else:\n",
        "    final_preds.append(\"negative\")\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4664/4664 [00:31<00:00, 147.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97gb4z6kngSy",
        "outputId": "a1f96715-c90c-44f0-cd1b-489beb0317cd"
      },
      "source": [
        "df_senti['sentiment'] = final_preds"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6z5pF0YnvSP",
        "outputId": "00d09f07-96ab-4f9d-c46f-9927f78476c6"
      },
      "source": [
        "df_sub  = df_senti.append(df_new_neu,ignore_index = False)\n",
        "df_sub =  df_sub.sort_values(by=['index'])\n",
        "print(len(df_sub))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gvageNEn3sU"
      },
      "source": [
        "df_sub.to_csv('./new_predictions.csv',index=False)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R8XiG7epAJR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
